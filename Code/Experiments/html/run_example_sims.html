
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>run_example_sims</title><meta name="generator" content="MATLAB 8.5"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2015-11-24"><meta name="DC.source" content="run_example_sims.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#3">task properties consistent across all tasks</a></li><li><a href="#4">trunk</a></li><li><a href="#5">toeplitz</a></li><li><a href="#6">fat tails</a></li><li><a href="#7">save generalizations</a></li><li><a href="#8">set figure parameters that are consistent across panels</a></li><li><a href="#10">print figure</a></li></ul></div><pre class="codeinput"><span class="keyword">function</span> [T,S,P,task] = run_example_sims(task)
</pre><pre class="codeinput"><span class="comment">% generate example simulations and run various classification algorithsm</span>
<span class="comment">% clearvars,</span>
clc,
fpath = mfilename(<span class="string">'fullpath'</span>);
findex=strfind(fpath,<span class="string">'/'</span>);
p = genpath(fpath(1:findex(end-2)));
addpath(p);
</pre><h2>task properties consistent across all tasks<a name="3"></a></h2><p>clear task T S P</p><pre class="codeinput"><span class="keyword">if</span> nargin==0
    task=struct;
<span class="keyword">end</span>

<span class="keyword">if</span> ~isfield(task,<span class="string">'algs'</span>),   task.algs={<span class="string">'LOL'</span>;<span class="string">'ROAD'</span>}; <span class="keyword">end</span>
<span class="keyword">if</span> ~isfield(task,<span class="string">'ntrials'</span>),task.ntrials=50; <span class="keyword">end</span>
<span class="keyword">if</span> ~isfield(task,<span class="string">'simulation'</span>),         task.simulation=1; <span class="keyword">end</span>
<span class="keyword">if</span> ~isfield(task,<span class="string">'percent_unlabeled'</span>),  task.percent_unlabeled=0; <span class="keyword">end</span>
<span class="keyword">if</span> ~isfield(task,<span class="string">'types'</span>),  task.types={<span class="string">'DENL'</span>;<span class="string">'NENL'</span>}; <span class="keyword">end</span>
<span class="keyword">if</span> ~isfield(task,<span class="string">'ntrain'</span>), task.ntrain=100; <span class="keyword">end</span>
<span class="keyword">if</span> ~isfield(task,<span class="string">'ks'</span>),     task.ks=unique(round(logspace(0,log10(task.ntrain-1),50))); <span class="keyword">end</span>
<span class="keyword">if</span> ~isfield(task,<span class="string">'savestuff'</span>), task.savestuff=1; <span class="keyword">end</span>
<span class="keyword">if</span> ~isfield(task,<span class="string">'plot'</span>), task.plot=1; <span class="keyword">end</span>
task=orderfields(task);
</pre><h2>trunk<a name="4"></a></h2><pre class="codeinput">j=1;
task1=task;
task1.name=<span class="string">'trunk4, D=100'</span>;
task1.rotate=true;
[T{j},S{j},P{j}] = run_task(task1);
</pre><pre class="codeoutput">
T = 

                    D: 100
                 Kmax: 99
                Nalgs: 2
                  Nks: 34
            QDA_model: 1
                 algs: {2x1 cell}
                   ks: [1x34 double]
                    n: 600
                 name: 'trunk4, D=100'
                ntest: 500
               ntrain: 100
              ntrials: 50
    percent_unlabeled: 0
                 plot: 1
               rotate: 1
            savestuff: 1
           simulation: 1
                types: {2x1 cell}

Starting parallel pool (parpool) using the 'local' profile ... connected to 2 workers.
WARNING: the linear classifier barfed during embedding dimension 99
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
trial # 30
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
trial # 10
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
trial # 20
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
trial # 40
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
trial # 50
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
The pooled covariance matrix of TRAINING must be positive definite.
WARNING: the linear classifier barfed during embedding dimension 99
The pooled covariance matrix of TRAINING must be positive definite.
</pre><pre class="codeoutput error">Error using save
Cannot create 'trunk4, D=100.mat' because '/Users/jovo/Research/Projects/Jovo/LOL/Data/Results' does not exist.

Error in run_task (line 34)
    save([rootDir, 'Data/Results/', name],'T','S','P'), 

Error in run_example_sims (line 34)
[T{j},S{j},P{j}] = run_task(task1);
</pre><h2>toeplitz<a name="5"></a></h2><pre class="codeinput">j=2;
task1=task;
task1.name=<span class="string">'toeplitz, D=100'</span>;
[T{j},S{j},P{j}] = run_task(task1);
</pre><h2>fat tails<a name="6"></a></h2><pre class="codeinput">j=3;
task1=task;
task1.name=<span class="string">'fat tails, D=100'</span>;
task1.rotate=true;
task1.QDA_model=false;
[T{j},S{j},P{j}] = run_task(task1);
</pre><h2>save generalizations<a name="7"></a></h2><pre class="codeinput"><span class="keyword">if</span> task.savestuff
    save([fpath(1:findex(end-2)), <span class="string">'Data/Results/example_sims'</span>],<span class="string">'T'</span>,<span class="string">'S'</span>,<span class="string">'P'</span>,<span class="string">'task'</span>)
<span class="keyword">end</span>
<span class="comment">% load([fpath(1:findex(end-2)), 'Data/Results/example_sims'])</span>
</pre><h2>set figure parameters that are consistent across panels<a name="8"></a></h2><pre class="codeinput"><span class="keyword">if</span> task.plot
</pre><pre class="codeinput">    clear <span class="string">G</span> <span class="string">F</span> <span class="string">H</span>
    h=figure(1); clf,
    G.plot_chance=false;
    G.plot_bayes=false;
    G.plot_risk=false;
    G.plot_time=false;
    G.Nrows=3;
    G.Ncols=3;
    G.legendOn=0;
    G.legend = {<span class="string">'LOL'</span>;<span class="string">'PCA'</span>};

    G.linestyle={<span class="string">'-'</span>;<span class="string">'-'</span>;<span class="string">'-'</span>;<span class="string">'-'</span>;<span class="string">'-'</span>;<span class="string">'-'</span>;<span class="string">'-'</span>};
    G.ytick=[0.1:.1:.5];
    G.ylim=[0, 0.5];

    G.xtick=[25:25:task.ntrain];
    G.xlim=[0, 80];

    G.yscale=<span class="string">'log'</span>;

    orange=[1 0.6 0];
    gray=0.75*[1 1 1];
    purple=[0.5 0 0.5];
    G.colors = {<span class="string">'g'</span>;<span class="string">'m'</span>;<span class="string">'c'</span>};
    dd=2;
    gg=dd*0.75;
    G.ti=[1,3,2]; <span class="comment">% order of ticks</span>

    <span class="comment">% sample</span>

    <span class="keyword">for</span> j=1:length(T)
        task1=T{j};
        task1.rotate=false;
        [task1, X, Y, PP] = get_task(task1);

        Z = parse_data(X,Y,task1.ntrain,task1.ntest,0);

        <span class="keyword">if</span> j~=2
            subplot(G.Nrows,G.Ncols,j),
        <span class="keyword">else</span>
            subplot(<span class="string">'position'</span>,[.41 .71 .10 .21]),
        <span class="keyword">end</span>
        hold <span class="string">on</span>
        maxd=task1.ntrain;
        mu=PP.mu; mu=mu/max(mu(:));
        plot(1:length(mu(:,2)),mu(:,1),<span class="string">'color'</span>,<span class="string">'k'</span>,<span class="string">'linestyle'</span>,<span class="string">'-'</span>,<span class="string">'linewidth'</span>,1.5)
        <span class="comment">%     plot(1:length(mu(:,2)),mu(:,2),'color','w','linestyle','-','linewidth',1.5)</span>
        <span class="comment">% hold on</span>
        dashline(1:length(mu(:,2)),mu(:,2),dd,gg,dd,gg,<span class="string">'color'</span>,gray,<span class="string">'linewidth'</span>,1.5)

        xlim=[0,100];
        ylim=[-1,1];
        xtick=50:50:xlim(end);

        <span class="keyword">if</span> j==1
            title(<span class="string">'(A) Rotated Trunk'</span>)
            ylabel(<span class="string">'means'</span>)
            ytick=[-1,0,1];
        <span class="keyword">elseif</span> j==2,
            <span class="comment">%         title('')</span>
            xlim=[1,4];
            xtick=2:2:xlim(end);
            xlabel(<span class="string">'ambient dimension index'</span>);
            ytick=[];
        <span class="keyword">elseif</span> j==3,
            title(<span class="string">'(C) Fat Tails'</span>)
            ytick=[];
        <span class="keyword">end</span>

        set(gca,<span class="string">'XTick'</span>,xtick,<span class="string">'Xlim'</span>,xlim,<span class="string">'ylim'</span>,ylim,<span class="string">'ytick'</span>,ytick)
        grid(<span class="string">'off'</span>), <span class="comment">%axis('tight')</span>


        <span class="keyword">if</span> j==2
            subplot(<span class="string">'position'</span>,[.58 .71 .07 .21]), hold <span class="string">on</span>
            plot(1:length(mu(:,2)),mu(:,1),<span class="string">'color'</span>,<span class="string">'k'</span>,<span class="string">'linestyle'</span>,<span class="string">'-'</span>,<span class="string">'linewidth'</span>,1.5)
            dashline(1:length(mu(:,2)),mu(:,2),dd,gg,dd,gg,<span class="string">'color'</span>,gray,<span class="string">'linewidth'</span>,1.5)
            set(gca,<span class="string">'XTick'</span>,xtick,<span class="string">'Xlim'</span>,xlim,<span class="string">'xlim'</span>,[98,100],<span class="string">'xtick'</span>,0:2:100,<span class="string">'ytick'</span>,[],<span class="string">'Ycolor'</span>,<span class="string">'w'</span>)
            annotation(<span class="string">'textbox'</span>, [0.51,0.76,0.10,0.1],<span class="keyword">...</span>
                <span class="string">'String'</span>, <span class="string">'...'</span>,<span class="string">'EdgeColor'</span>,<span class="string">'w'</span>,<span class="string">'FontSize'</span>,16);
            annotation(<span class="string">'textbox'</span>, [0.43,0.89,0.10,0.1],<span class="keyword">...</span>
                <span class="string">'String'</span>, <span class="string">'(B) Toeplitz'</span>,<span class="string">'EdgeColor'</span>,<span class="string">'w'</span>);

        <span class="keyword">end</span>

        <span class="keyword">if</span> j==1
            F=G;
            F.doxlabel=false;
            F.title=<span class="string">''</span>;
            F.ylabel=<span class="string">'error rate'</span>;
            F.ytick=[0.05, 0.15, 0.35]; <span class="comment">%[0.06, [0.1:0.1:0.3]];</span>
            F.ylim=[0.03,0.5];
            plot_Lhat(T{j},S{j},F,2*F.Ncols+j)
            ids=1:10:100;
        <span class="keyword">elseif</span> j==2
            F=G;
            F.doxlabel=false;
            F.ylim=[0.30,0.5];
            F.ytick=[0:0.1:0.5];
            F.title=<span class="string">''</span>;
            F.xlabel=<span class="string">'total # of embedded dimensions'</span>;
            plot_Lhat(T{j},S{j},F,2*F.Ncols+j)
            ids=1:10;
        <span class="keyword">elseif</span> j==3
            F=G;
            F.doxlabel=false;
            F.ylim=[0.15,0.5];
            F.ytick=[0:0.1:0.5];
            F.title=<span class="string">''</span>;
            F.xticklabel=[];
            plot_Lhat(T{j},S{j},F,2*F.Ncols+j)
            ids=1:10:100;
        <span class="keyword">end</span>

        subplot(G.Nrows,G.Ncols,G.Ncols+j)
        imagesc(PP.Sigma(ids,ids))
        set(gca,<span class="string">'xticklabel'</span>,[],<span class="string">'yticklabel'</span>,[])
        colormap(<span class="string">'bone'</span>)
        axis(<span class="string">'square'</span>)
        <span class="keyword">if</span> j==1, ylabel(<span class="string">'covariance'</span>), <span class="keyword">end</span>
    <span class="keyword">end</span>
</pre><h2>print figure<a name="10"></a></h2><pre class="codeinput">    <span class="keyword">if</span> task.savestuff
        H.wh=[F.Ncols F.Nrows]*1.4;
        H.fname=[fpath(1:findex(end-2)), <span class="string">'Figs/example_sims'</span>];
        print_fig(h,H)
    <span class="keyword">end</span>
</pre><pre class="codeinput"><span class="keyword">end</span>
</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2015a</a><br></p></div><!--
##### SOURCE BEGIN #####
function [T,S,P,task] = run_example_sims(task)

% generate example simulations and run various classification algorithsm
% clearvars,
clc,
fpath = mfilename('fullpath');
findex=strfind(fpath,'/');
p = genpath(fpath(1:findex(end-2)));
addpath(p);

%% task properties consistent across all tasks
% clear task T S P
if nargin==0
    task=struct;
end

if ~isfield(task,'algs'),   task.algs={'LOL';'ROAD'}; end
if ~isfield(task,'ntrials'),task.ntrials=50; end
if ~isfield(task,'simulation'),         task.simulation=1; end
if ~isfield(task,'percent_unlabeled'),  task.percent_unlabeled=0; end
if ~isfield(task,'types'),  task.types={'DENL';'NENL'}; end
if ~isfield(task,'ntrain'), task.ntrain=100; end
if ~isfield(task,'ks'),     task.ks=unique(round(logspace(0,log10(task.ntrain-1),50))); end
if ~isfield(task,'savestuff'), task.savestuff=1; end
if ~isfield(task,'plot'), task.plot=1; end
task=orderfields(task);

%% trunk

j=1;
task1=task;
task1.name='trunk4, D=100';
task1.rotate=true;
[T{j},S{j},P{j}] = run_task(task1);


%% toeplitz

j=2;
task1=task;
task1.name='toeplitz, D=100';
[T{j},S{j},P{j}] = run_task(task1);

%% fat tails

j=3;
task1=task;
task1.name='fat tails, D=100';
task1.rotate=true;
task1.QDA_model=false;
[T{j},S{j},P{j}] = run_task(task1);


%% save generalizations

if task.savestuff
    save([fpath(1:findex(end-2)), 'Data/Results/example_sims'],'T','S','P','task')
end
% load([fpath(1:findex(end-2)), 'Data/Results/example_sims'])


%% set figure parameters that are consistent across panels
%

if task.plot
    clear G F H
    h=figure(1); clf,
    G.plot_chance=false;
    G.plot_bayes=false;
    G.plot_risk=false;
    G.plot_time=false;
    G.Nrows=3;
    G.Ncols=3;
    G.legendOn=0;
    G.legend = {'LOL';'PCA'};
    
    G.linestyle={'-';'-';'-';'-';'-';'-';'-'};
    G.ytick=[0.1:.1:.5];
    G.ylim=[0, 0.5];
    
    G.xtick=[25:25:task.ntrain];
    G.xlim=[0, 80];
    
    G.yscale='log';
    
    orange=[1 0.6 0];
    gray=0.75*[1 1 1];
    purple=[0.5 0 0.5];
    G.colors = {'g';'m';'c'};
    dd=2;
    gg=dd*0.75;
    G.ti=[1,3,2]; % order of ticks
    
    % sample
    
    for j=1:length(T)
        task1=T{j};
        task1.rotate=false;
        [task1, X, Y, PP] = get_task(task1);
        
        Z = parse_data(X,Y,task1.ntrain,task1.ntest,0);
        
        if j~=2
            subplot(G.Nrows,G.Ncols,j),
        else
            subplot('position',[.41 .71 .10 .21]),
        end
        hold on
        maxd=task1.ntrain;
        mu=PP.mu; mu=mu/max(mu(:));
        plot(1:length(mu(:,2)),mu(:,1),'color','k','linestyle','-','linewidth',1.5)
        %     plot(1:length(mu(:,2)),mu(:,2),'color','w','linestyle','-','linewidth',1.5)
        % hold on
        dashline(1:length(mu(:,2)),mu(:,2),dd,gg,dd,gg,'color',gray,'linewidth',1.5)
        
        xlim=[0,100];
        ylim=[-1,1];
        xtick=50:50:xlim(end);
        
        if j==1
            title('(A) Rotated Trunk')
            ylabel('means')
            ytick=[-1,0,1];
        elseif j==2,
            %         title('')
            xlim=[1,4];
            xtick=2:2:xlim(end);
            xlabel('ambient dimension index');
            ytick=[];
        elseif j==3,
            title('(C) Fat Tails')
            ytick=[];
        end
        
        set(gca,'XTick',xtick,'Xlim',xlim,'ylim',ylim,'ytick',ytick)
        grid('off'), %axis('tight')
        
        
        if j==2
            subplot('position',[.58 .71 .07 .21]), hold on
            plot(1:length(mu(:,2)),mu(:,1),'color','k','linestyle','-','linewidth',1.5)
            dashline(1:length(mu(:,2)),mu(:,2),dd,gg,dd,gg,'color',gray,'linewidth',1.5)
            set(gca,'XTick',xtick,'Xlim',xlim,'xlim',[98,100],'xtick',0:2:100,'ytick',[],'Ycolor','w')
            annotation('textbox', [0.51,0.76,0.10,0.1],...
                'String', '...','EdgeColor','w','FontSize',16);
            annotation('textbox', [0.43,0.89,0.10,0.1],...
                'String', '(B) Toeplitz','EdgeColor','w');
            
        end
        
        if j==1
            F=G;
            F.doxlabel=false;
            F.title='';
            F.ylabel='error rate';
            F.ytick=[0.05, 0.15, 0.35]; %[0.06, [0.1:0.1:0.3]];
            F.ylim=[0.03,0.5];
            plot_Lhat(T{j},S{j},F,2*F.Ncols+j)
            ids=1:10:100;
        elseif j==2
            F=G;
            F.doxlabel=false;
            F.ylim=[0.30,0.5];
            F.ytick=[0:0.1:0.5];
            F.title='';
            F.xlabel='total # of embedded dimensions';
            plot_Lhat(T{j},S{j},F,2*F.Ncols+j)
            ids=1:10;
        elseif j==3
            F=G;
            F.doxlabel=false;
            F.ylim=[0.15,0.5];
            F.ytick=[0:0.1:0.5];
            F.title='';
            F.xticklabel=[];
            plot_Lhat(T{j},S{j},F,2*F.Ncols+j)
            ids=1:10:100;
        end
        
        subplot(G.Nrows,G.Ncols,G.Ncols+j)
        imagesc(PP.Sigma(ids,ids))
        set(gca,'xticklabel',[],'yticklabel',[])
        colormap('bone')
        axis('square')
        if j==1, ylabel('covariance'), end
    end
    
    
    %% print figure
    if task.savestuff
        H.wh=[F.Ncols F.Nrows]*1.4;
        H.fname=[fpath(1:findex(end-2)), 'Figs/example_sims'];
        print_fig(h,H)
    end
end




##### SOURCE END #####
--></body></html>